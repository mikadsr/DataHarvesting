---
title: "Data Harvesting final"
format: html
editor: visual
---

pakcages

```{r echo=FALSE}
#install.packages("scrapex")
#install.packages("magrittr")
library(scrapex)
library(xml2)
library(magrittr)
library(lubridate)
library(dplyr)
library(tidyr)
library(httr)
library(rvest)
library(janitor)
library(stringr)


```

```{r}
sider_link<- "http://sideeffects.embl.de/drugs/"
```

docker pull selenium/standalone-firefox:2.53.0
sido docker -d -p 4445:4444 selenium/standalone-firefox:2.53.0

## Setting up Selenium browser

To do before

-   Download Java [here](https://www.oracle.com/java/technologies/downloads/)

-   Ask for Java location on terminal\>\> where java

-   Download Firefox [here](https://www.mozilla.org/es-ES/firefox/new/)

Run the following code for attaching JAVA

```{r attach Java}
#Sys.getenv("JAVA_HOME")
#Sys.setenv(JAVA_HOME = "C:/Program Files (x86)/Common Files/Oracle/ava/javapath/java.exe") 
#Sys.getenv("PATH")
#install.packages("RSelenium", dependencies=TRUE)


```

Now quit and re star R before running the the next chunk of code.

As described before, Selenium tries to mimic a human. This literally means that we need to open a browser. In RSelenium we do that with the rsDriver function. This function initializes the browser and opens it for us:

A port is just a number. they represent channels through which the computer communicates. When we deploy a docker image, we assign it a port to 'talk' through.

The output the following code will gives is just telling us which drivers it is currently downloading. 

```{r set up Selenium browser}
library(RSelenium)

remDr <- rsDriver(port = 4444L, 
                  #If port is taken just try dif. value
                  browser = "firefox",
                  verbose=F,
                  chromever=NULL)

```

`RSelenium` opened a browser which you **don't need to touch**. Everything you do on this browser will be performed using the object `remDr`, where the browser was initiated.`remDr` has a property called `client` from where you can `navigate` to a website.

```{r navigating the link}
remDr$client$navigate(sider_link)


```

## Navigating our site
We will use `client ` a lot, so we will save it in our `driver` object. 
```{r}
driver <- remDr$client

driver$findElement(value = "(//*[@id='toggleExpand'])")$clickElement()


#Then we get the source code of the web into an HTML string
page_source <- driver$getPageSource()[[1]]

#With the HTML code as a string, weâ€™re on familiar ground. We can use read_html to read it.
html_code <-
  page_source |> 
  read_html()



```

## Scraping

Here I'm trying the link for Desflurane (N01AB)

```{r scraping a table}

link1<- "http://sideeffects.embl.de/drugs/42113/"

#Get all tables from website
table<- link1 |> 
  read_html() |> 
  html_table()

#Extract only table 1, as it is the one with the data we want.
desflurane <-  table[[1]] |> 
  dplyr::select(`Side effect`, `Data for drug`) |> 
  clean_names() |> 
  filter(!grepl("postmarketing", data_for_drug, ignore.case = TRUE)) |> 
  filter(across(everything(), ~ !is.na(.) & !(. == "")))


desflurane 

```
